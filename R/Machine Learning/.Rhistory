model1 = train(y~ ., data=vowel.train, method="rf", prox=TRUE, ntree=500)
# predict outcome for test data set using the random forest model
pred1 = predict(model1, vowel.test)
# tabulate results:
table(pred1,vowel.test$y)
# calculate correct predictions:
sum(diag(table(pred1,vowel.test$y)))
# Fit (2) a boosted predictor using the "gbm" method relating the factor variable y to the remaining variables:
model2= train(y~ ., data=vowel.train, method="gbm", verbose=F)
#-----------------------------------------------------------------------------------------------
# Question 1
# Load the vowel.train and vowel.test data sets:
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
# Set the variable y to be a factor variable in both the training and test set.
vowel.train$y=as.factor(vowel.train$y)
vowel.test$y=as.factor(vowel.test$y)
set.seed(33833)
# Fit (1) a random forest predictor relating the factor variable y to the remaining variables:
model1 = train(y~ ., data=vowel.train, method="rf", prox=TRUE, ntree=500)
# predict outcome for test data set using the random forest model
pred1 = predict(model1, vowel.test)
# tabulate results:
table(pred1,vowel.test$y)
# calculate correct predictions:
sum(diag(table(pred1,vowel.test$y)))/462
# Fit (2) a boosted predictor using the "gbm" method relating the factor variable y to the remaining variables:
model2= train(y~ ., data=vowel.train, method="gbm", verbose=F)
pred2 = predict(model2, vowel.test)
# tabulate results:
table(pred2,vowel.test$y)
# calculate correct predictions:
sum(diag(table(pred2,vowel.test$y)))/462
#-----------------------------------------------------------------------------------------------
# Question 1
# Load the vowel.train and vowel.test data sets:
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
# Set the variable y to be a factor variable in both the training and test set.
vowel.train$y=as.factor(vowel.train$y)
vowel.test$y=as.factor(vowel.test$y)
set.seed(33833)
# Fit (1) a random forest predictor relating the factor variable y to the remaining variables:
model1 = train(y~ ., data=vowel.train, method="rf", prox=TRUE, ntree=500)
# predict outcome for test data set using the random forest model
pred1 = predict(model1, vowel.test)
# Results
confusionMatrix(vowel.test$y, pred1)
# Fit (2) a boosted predictor using the "gbm" method relating the factor variable y to the remaining variables:
model2= train(y~ ., data=vowel.train, method="gbm", verbose=F)
pred2 = predict(model2, vowel.test)
# Results
confusionMatrix(vowel.test$y, pred2)
#-----------------------------------------------------------------------------------------------
#Question 2
#Load the Alzheimer's data using the following commands
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
#Set the seed to 62433 and predict diagnosis with all the other variables using a random forest ("rf"),
#boosted trees ("gbm") and linear discriminant analysis ("lda") model.
set.seed(62433)
model1 = train(diagnosis~ ., data=vowel.train, method="rf", prox=TRUE, ntree=500)
model2 = train(diagnosis~ ., data=vowel.train, method="gbm", verbose=F)
model3 = train(diagnosis~ ., data=vowel.train, method="lda")
pred1 = predict(model1, testing)
pred2 = predict(model2, testing)
pred3 = predict(model3, testing)
predDf = data.frame(rf.pred=pred1,gbm.pred = pred2, lda.pred = pred3, testing$diagnosis)
#Set the seed to 62433 and predict diagnosis with all the other variables using a random forest ("rf"),
#boosted trees ("gbm") and linear discriminant analysis ("lda") model.
set.seed(62433)
model1 = train(diagnosis~ ., data=training, method="rf", prox=TRUE, ntree=500)
model2 = train(diagnosis~ ., data=training, method="gbm", verbose=F)
model3 = train(diagnosis~ ., data=training, method="lda")
predDf = data.frame(rf.pred=pred1, gbm.pred = pred2, lda.pred = pred3, testing$diagnosis)
pred1 = predict(model1, testing)
pred2 = predict(model2, testing)
pred3 = predict(model3, testing)
predDf = data.frame(rf.pred =pred1, gbm.pred = pred2, lda.pred = pred3, testing$diagnosis)
View(predDf)
predDf = data.frame(rf.pred =pred1, gbm.pred = pred2, lda.pred = pred3, diagnosis=testing$diagnosis)
comboModel = train(diagnosis~ .,method="rf", prox=TRUE, ntree=500)
#Stack the predictions together using random forests ("rf"):
combinedTestData = data.frame(rf.pred =pred1, gbm.pred = pred2, lda.pred = pred3, diagnosis=testing$diagnosis)
comboModel = train(diagnosis~ .,data=combinedTestData, method="rf", prox=TRUE, ntree=500)
# use the resultant model to predict on the test set
comb.pred.test <- predict(comboModel, combinedTestData)
#Stack the predictions together using random forests ("rf"):
combinedTestData = data.frame(rf.pred = pred1, gbm.pred = pred2, lda.pred = pred3, diagnosis=testing$diagnosis)
comboModel = train(diagnosis~ .,data = combinedTestData, method="rf", prox=TRUE, ntree=500)
View(combinedTestData)
combinedTestData = data.frame(rf.pred = pred1, gbm.pred = pred2, lda.pred = pred3, diagnosis=testing$diagnosis)
comboModel = train(diagnosis~ .,data = combinedTestData, method="gam")
# use the resultant model to predict on the test set
comb.pred.test <- predict(comboModel, combinedTestData)
#Stack the predictions together using random forests ("rf"):
combinedTestData = data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis)
comboModel = train(diagnosis~ .,data = combinedTestData, method="rf", prox=TRUE, ntree=500)
#Stack the predictions together using random forests ("rf"):
combinedTestData = data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis)
model4 = train(diagnosis~ .,data = combinedTestData, method="rf", prox=TRUE, ntree=500)
# use the resultant model to predict on the test set
pred1 <- predict(model4, combinedTestData)
#Stack the predictions together using random forests ("rf"):
combinedTestData = data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis)
model4 = train(diagnosis~ .,data = combinedTestData, method="rf", prox=TRUE, ntree=500)
# use the resultant model to predict on the test set
pred4 <- predict(model4, testing)
# confusion matrixes
c1 = confusionMatrix(predict1, testing$diagnosis)
c2 = confusionMatrix(predict2, testing$diagnosis)
c3 = confusionMatrix(predict3, testing$diagnosis)
c4 = confusionMatrix(predict4, testing$diagnosis)
#Stack the predictions together using random forests ("rf"):
combinedTestData = data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis)
model4 = train(diagnosis~ .,data = combinedTestData, method="rf", prox=TRUE, ntree=500)
# use the resultant model to predict on the test set
pred4 <- predict(model4, testing)
# confusion matrixes
c1 = confusionMatrix(pred1, testing$diagnosis)
c2 = confusionMatrix(pred2, testing$diagnosis)
c3 = confusionMatrix(pred3, testing$diagnosis)
c4 = confusionMatrix(pred4, testing$diagnosis)
#Stack the predictions together using random forests ("rf"):
combo = data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis)
model4 = train(diagnosis~ .,data = combo, method="rf", prox=TRUE, ntree=500)
# use the resultant model to predict on the test set
pred4 = predict(model4, testing)
# confusion matrixes
confusionMatrix(pred1, testing$diagnosis)
confusionMatrix(pred2, testing$diagnosis)
confusionMatrix(pred3, testing$diagnosis)
confusionMatrix(pred4, testing$diagnosis)
#Question 2
#Load the Alzheimer's data using the following commands
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
#Set the seed to 62433 and predict diagnosis with all the other variables using a random forest ("rf"),
#boosted trees ("gbm") and linear discriminant analysis ("lda") model:
set.seed(62433)
model1 = train(diagnosis~ ., data=training, method="rf", prox=TRUE, ntree=500)
model2 = train(diagnosis~ ., data=training, method="gbm", verbose=F)
model3 = train(diagnosis~ ., data=training, method="lda")
pred1 = predict(model1, testing)
pred2 = predict(model2, testing)
pred3 = predict(model3, testing)
#Stack the predictions together using random forests ("rf"):
combo = data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis)
model4 = train(diagnosis~ .,data = combo, method="rf", prox=TRUE, ntree=500)
# use the resultant model to predict on the test set:
pred4 = predict(model4, testing)
# confusion matrixes:
confusionMatrix(pred1, testing$diagnosis)
confusionMatrix(pred2, testing$diagnosis)
confusionMatrix(pred3, testing$diagnosis)
confusionMatrix(pred4, testing$diagnosis)
#Set the seed to 62433 and predict diagnosis with all the other variables using a random forest ("rf"),
#boosted trees ("gbm") and linear discriminant analysis ("lda") model:
set.seed(62433)
model1 = train(diagnosis~ ., data=training, method="rf", trControl = trainControl(number = 4))
model2 = train(diagnosis~ ., data=training, method="gbm", verbose=F)
model3 = train(diagnosis~ ., data=training, method="lda")
pred1 = predict(model1, testing)
pred2 = predict(model2, testing)
pred3 = predict(model3, testing)
#Stack the predictions together using random forests ("rf"):
combo = data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis)
model4 = train(diagnosis~ .,data = combo, method="rf", trControl = trainControl(number = 4))
# use the resultant model to predict on the test set:
pred4 = predict(model4, testing)
# confusion matrixes:
confusionMatrix(pred1, testing$diagnosis)
confusionMatrix(pred2, testing$diagnosis)
confusionMatrix(pred3, testing$diagnosis)
confusionMatrix(pred4, testing$diagnosis)
#-----------------------------------------------------------------------------------------------
#Question 3
#Load the concrete data with the commands:
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
View(training)
# load lars package
library(lars)
# perform lasso regression
y <- as.numeric(training[,9])
x <- as.matrix(training[,1:8])
model.lasso = lars(as.matrix(x), y, type="lasso", trace=TRUE)
lambda.lasso = c(model.lasso$lambda,0)
beta = coef(model.lasso)
install.packages("lars")
# load lars package
library(lars)
# perform lasso regression
y <- as.numeric(training[,9])
x <- as.matrix(training[,1:8])
model.lasso = lars(as.matrix(x), y, type="lasso", trace=TRUE)
lambda.lasso = c(model.lasso$lambda,0)
beta = coef(model.lasso)
?plot.enet
??plot.enet
# perform lasso regression
set.seed(233)
lasso.model = train(CompressiveStrength~., data=training, method="lasso")
# perform lasso regression
set.seed(233)
lasso.model = train(CompressiveStrength~., data=training, method="lasso")
plot.enet(lasso.model$finalModel, xvar="penalty", use.color=TRUE)
#-----------------------------------------------------------------------------------------------
#Question 5
#Load the concrete data with the commands:
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
#Set the seed to 325 and fit a support vector machine using the e1071 package to predict Compressive Strength using the default settings. Predict on the testing set. What is the RMSE?
require(e1071)
set.seed(325)
fit=svm(CompressiveStrength ~., data = training )
pred=predict(fit, testing)
accuracy(f = pred, x = testing$CompressiveStrength)
library(forecast)
accuracy(f = pred, x = testing$CompressiveStrength)
install.packages("forecast")
#-----------------------------------------------------------------------------------------------
#Question 5
#Load the concrete data with the commands:
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
#Set the seed to 325 and fit a support vector machine using the e1071 package to predict Compressive Strength using the default settings. Predict on the testing set. What is the RMSE?
require(e1071)
set.seed(325)
fit=svm(CompressiveStrength ~., data = training )
pred=predict(fit, testing)
library(forecast)
accuracy(f = pred, x = testing$CompressiveStrength)
gaData <- read.csv("~/Programming/R/Machine Learning/gaData.csv")
View(gaData)
#Question 4
library(lubridate)  # For year() function below
dat = read.csv("~/Programming/R/Machine Learning/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
install.packages("lubridate")
#-----------------------------------------------------------------------------------------------
#Question 4
library(lubridate)  # For year() function below
dat = read.csv("~/Programming/R/Machine Learning/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
#Fit a model using the bats() function in the forecast package to the training time series:
model= bats(tstrain)
#Then forecast this model for the remaining time points:
fcast <- forecast(model, level = 95, h = h)
# forecast with a 95% ci
fcast = forecast(object = fit, level = 95); fcast
# test accuracy
accuracy(f = fcast, x = training$visitsTumblr)
# forecast with a 95% ci
fcast = forecast(object = model, level = 95); fcast
# test accuracy
accuracy(f = fcast, x = training$visitsTumblr)
#-----------------------------------------------------------------------------------------------
# Question 1
# Load the vowel.train and vowel.test data sets:
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
# Set the variable y to be a factor variable in both the training and test set.
vowel.train$y=as.factor(vowel.train$y)
vowel.test$y=as.factor(vowel.test$y)
set.seed(33833)
# Fit (1) a random forest predictor relating the factor variable y to the remaining variables:
model1 = train(y~ ., data=vowel.train, method="rf", prox=TRUE, ntree=500)
# predict outcome for test data set using the random forest model
pred1 = predict(model1, vowel.test)
# Results
confusionMatrix(vowel.test$y, pred1)
# Fit (2) a boosted predictor using the "gbm" method relating the factor variable y to the remaining variables:
model2= train(y~ ., data=vowel.train, method="gbm", verbose=F)
pred2 = predict(model2, vowel.test)
# Results
confusionMatrix(vowel.test$y, pred2)
pml.training <- read.csv("~/Programming/R/Machine Learning/pml-training.csv")
View(pml.training)
pml.testing <- read.csv("~/Programming/R/Machine Learning/pml-testing.csv")
View(pml.testing)
pml.training <- read.csv("~/Programming/R/Machine Learning/pml-training.csv")
pml.testing <- read.csv("~/Programming/R/Machine Learning/pml-testing.csv")
View(pml.testing)
pml.training = read.csv("pml-training.csv")
pml.training [, colSums(is.na(pml.training )) != nrow(pml.training )]
View(pml.training)
pml.training [, colSums(is.na(pml.training )) != nrow(pml.training )]
pml.training[ , colSums(is.na(pml.training)) == 0]
View(pml.training)
pml.training <- read.csv("~/Programming/R/Machine Learning/pml-training.csv")
View(pml.training)
pml.training = read.csv("pml-training.csv", na.strings=c("NA","NaN", " ") )
pml.training[ , colSums(is.na(pml.training)) == 0]
pml.testing <- read.csv("pml-testing.csv", na.strings=c("NA","NaN", " ") )
pml.training = read.csv("pml-training.csv", na.strings=c("NA","NaN", " ") )
pml.training[ , colSums(is.na(pml.training)) == 0]
pml.training = read.csv("pml-training.csv", na.strings=c("NA","NaN", " ") )
pml.training <- read.csv("~/Programming/R/Machine Learning/pml-training.csv", header=FALSE, na.strings="NA, NAN, \x0C \"")
View(pml.training)
pml.training = read.csv("~/Programming/R/Machine Learning/pml-training.csv", header=TRUE, na.strings=c("NA","NaN", " ") )
pml.training[ , colSums(is.na(pml.training)) == 0]
View(pml.training)
pml.training[ , colSums(is.na(pml.training)) == 0]
subset(pml.training, select=colMeans(is.na(pml.training)) == 0)
test = subset(pml.training, select=colMeans(is.na(pml.training)) == 0)
View(test)
pml.training = read.csv("~/Programming/R/Machine Learning/pml-training.csv", header=TRUE, na.strings=c("NA","NaN", " ") )
pml.training.clean = subset(pml.training, select=colMeans(is.na(pml.training)) == 0)
pml.testing = read.csv("pml-testing.csv", na.strings=c("NA","NaN", " ") )
pml.testing.clean = subset(pml.testing, select=colMeans(is.na(pml.testing)) == 0)
pml.testing = read.csv("~/Programming/R/Machine Learning/pml-testing.csv", na.strings=c("NA","NaN", " ") )
pml.testing.clean = subset(pml.testing, select=colMeans(is.na(pml.testing)) == 0)
View(pml.testing.clean)
pml.training = read.csv("~/Programming/R/Machine Learning/pml-training.csv", header=TRUE, na.strings=c("NA","NaN", '') )
pml.training.clean = subset(pml.training, select=colMeans(is.na(pml.training)) == 0)
View(pml.testing.clean)
View(pml.training.clean)
View(pml.testing.clean)
View(pml.testing)
head(pml.testing)
library(caret)
set.seed(3456)
inTrain = createDataPartition(pml.training$classe, p = .7, list = FALSE)
training = pml.training[inTrain,]
testing = pml.training[-inTrain,]
library("doMC")
# use 4 cores:
registerDoMC(cores=4)
# apply random forest:
modFit = train(classe ~ ., data = training, method="rf", prox=TRUE, ntree=100, allowParallel=TRUE)
# print results:
print(modFit$finalModel)
# predict outcome for test data set using the random forest model:
pred = predict(modFit,testing)
# logic value for whether or not the rf algorithm predicted correctly:
testing$predRight <- pred==testing$classe
# tabulate results:
table(pred,testing$Species)
registerDoMC(cores=4)
# apply random forest:
modFit = train(classe ~ ., data = training, method="rf", prox=TRUE, ntree=100, allowParallel=TRUE)
library("doMC")
# use 4 cores:
registerDoMC(cores=4)
# apply random forest:
modFit = train(classe ~ ., data = training, method="rf", prox=TRUE, ntree=100, allowParallel=TRUE)
setwd("~/Programming/R/Machine Learning")
# import data raw data:
pml.training.raw = read.csv("pml-training.csv", header=TRUE, na.strings=c("NA","NaN", '') )
pml.testing.raw = read.csv("pml-testing.csv", header=TRUE, na.strings=c("NA","NaN", " ") )
# commands to clean the raw data:
pml.training = subset(pml.training.raw , select=colMeans(is.na(pml.training.raw)) == 0)
pml.testing = subset(pml.testing.raw , select=colMeans(is.na(pml.testing.raw)) == 0)
# Remove first 7 columns:
pml.training = pml.training[c(-1:-7)]
pml.testing = pml.testing[c(-1:-7)]
# create test/train data sets:
library(caret)
set.seed(3456)
inTrain = createDataPartition(pml.training$classe, p = .7, list = FALSE)
training = pml.training[inTrain,]
testing = pml.training[-inTrain,]
modFit = train(classe ~ ., data = training, method="gbm", verbose=FALSE)
# fit classification tree as a model
modFit = train(classe ~ .,method="rpart",data=training)
# print the classification tree
print(modFit$finalModel)
# test the model
tree.pred = predict(modFit, testing, type='class')
confusionMatrix(tree.pred, testing$classe)
# Question 3
# Load the olive oil data using the commands:
library(pgmm)
data(olive)
olive = olive[,-1]
# fit classification tree as a model
modFit <- train(Area ~ .,method="rpart",data=olive)
# print the classification tree
print(modFit$finalModel)
# plot the classification tree
library(rattle)
fancyRpartPlot(modFit$finalModel)
newdata = as.data.frame(t(colMeans(olive)))
predict(modFit,newdata=newdata[-1])
# print results of model
confusionMatrix(testing$classe,predict(modelFit,testing))
print(modFit$finalModel)
# print results of model
confusionMatrix(testing$classe,predict(modFit,testing))
# fit classification tree as a model
modFit = train(classe ~ .,method="rpart",data=training)
# print the classification tree
print(modFit$finalModel)
# print results of model
confusionMatrix(testing$classe,predict(modFit,testing))
# import data raw data:
pml.training.raw = read.csv("pml-training.csv", header=TRUE, na.strings=c("NA","NaN", '') )
pml.testing.raw = read.csv("pml-testing.csv", header=TRUE, na.strings=c("NA","NaN", " ") )
# commands to clean the raw data:
pml.training = subset(pml.training.raw , select=colMeans(is.na(pml.training.raw)) == 0)
pml.testing = subset(pml.testing.raw , select=colMeans(is.na(pml.testing.raw)) == 0)
# Remove first 7 columns:
pml.training = pml.training[c(-1:-7)]
pml.testing = pml.testing[c(-1:-7)]
# create test/train data sets:
library(caret)
set.seed(3456)
inTrain = createDataPartition(pml.training$classe, p = .7, list = FALSE)
training = pml.training[inTrain,]
testing = pml.training[-inTrain,]
# fit classification tree as a model
modFit = train(classe ~ .,method="rpart", preProcess = c("center", "scale"), data=training)
# print the classification tree
print(modFit$finalModel)
# print results of model
confusionMatrix(testing$classe,predict(modFit,testing))
# apply random forest
modFit = randomForest(outcome ~ ., data=train, method="rf", prox=TRUE, do.trace=TRUE, ntree=10)
library(randomForest)
# apply random forest
modFit = randomForest(outcome ~ ., data=train, method="rf", prox=TRUE, do.trace=TRUE, ntree=10)
library(randomForest)
# apply random forest
modFit = randomForest(outcome ~ ., data=training, method="rf", prox=TRUE, do.trace=TRUE, ntree=10)
library(randomForest)
# apply random forest
modFit = randomForest(classe ~ ., data=training, method="rf", prox=TRUE, do.trace=TRUE, ntree=10)
library(randomForest)
# apply random forest
modFit = randomForest(classe ~ ., data=training, method="rf", prox=TRUE, do.trace=TRUE, ntree=50)
```{r}
# apply random forest
modFit = train(classe ~ ., data=training, method="rf", prox=TRUE, do.trace=TRUE, ntree=50)
# Use 5 folds for cross-validation
trControl = trainControl(method = "cv", number = 5)
# apply random forest
modFit = train(classe ~ ., data=training, method="rf", trControl = trControl, prox=TRUE, do.trace=TRUE, ntree=10)
# predict outcome for test data set using the random forest model
pred = predict(modFit,testing)
# print confusion matrix:
confusionMatrix(pred, testing)
# print confusion matrix:
confusionMatrix(pred, data=testing)
# print confusion matrix:
confusionMatrix(pred, testing$classe)
# Set a random seed (so you will get the same results as me)
set.seed(42)
# Use 10 folds for cross-validation
trControl = trainControl(method = "cv", number = 10)
# apply random forest
modFit = train(classe ~ ., data=training, method="rf", trControl = trControl, prox=TRUE, do.trace=TRUE, ntree=2)
# Set a random seed
set.seed(42)
# Use 10 folds for cross-validation
trControl = trainControl(method = "cv", number = 5)
# apply random forest
modFit = train(classe ~ ., data=training, method="rf", trControl = trControl, prox=TRUE, do.trace=TRUE, ntree=5)
# predict outcome for test data set using the random forest model
pred = predict(modFit,testing)
# print confusion matrix:
confusionMatrix(pred, testing$classe)
print(modFit)
print(modFit$finalModel)
# Set a random seed
set.seed(42)
# Use 10 folds for cross-validation
trControl = trainControl(method = "cv", number = 5)
# apply random forest
modFit = train(classe ~ ., data=training, method="rf", trControl = trControl, prox=TRUE, do.trace=TRUE, ntree=10)
print(modFit)
print(modFit$finalModel)
# predict outcome for test data set using the random forest model
pred = predict(modFit,testing)
# print confusion matrix:
confusionMatrix(pred, testing$classe)
