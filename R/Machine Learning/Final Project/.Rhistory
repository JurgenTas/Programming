table(pred2,vowel.test$y)
# Fit (2) a boosted predictor using the "gbm" method relating the factor variable y to the remaining variables:
model2= train(y~ ., data=vowel.train, method="gbm", verbose=F)
pred2 = predict(model2, vowel.test)
# tabulate results
table(pred2,vowel.test$y)
#-----------------------------------------------------------------------------------------------
# Question 1
# Load the vowel.train and vowel.test data sets:
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
# Set the variable y to be a factor variable in both the training and test set.
vowel.train$y=as.factor(vowel.train$y)
vowel.test$y=as.factor(vowel.test$y)
set.seed(33833)
# Fit (1) a random forest predictor relating the factor variable y to the remaining variables:
model1 = train(y~ ., data=vowel.train, method="rf", prox=TRUE, ntree=500)
# predict outcome for test data set using the random forest model
pred1 = predict(model1, vowel.test)
# tabulate results:
table(pred1,vowel.test$y)
# calculate correct predictions:
sum(diag(table(pred1,vowel.test$y)))
# Fit (2) a boosted predictor using the "gbm" method relating the factor variable y to the remaining variables:
model2= train(y~ ., data=vowel.train, method="gbm", verbose=F)
#-----------------------------------------------------------------------------------------------
# Question 1
# Load the vowel.train and vowel.test data sets:
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
# Set the variable y to be a factor variable in both the training and test set.
vowel.train$y=as.factor(vowel.train$y)
vowel.test$y=as.factor(vowel.test$y)
set.seed(33833)
# Fit (1) a random forest predictor relating the factor variable y to the remaining variables:
model1 = train(y~ ., data=vowel.train, method="rf", prox=TRUE, ntree=500)
# predict outcome for test data set using the random forest model
pred1 = predict(model1, vowel.test)
# tabulate results:
table(pred1,vowel.test$y)
# calculate correct predictions:
sum(diag(table(pred1,vowel.test$y)))/462
# Fit (2) a boosted predictor using the "gbm" method relating the factor variable y to the remaining variables:
model2= train(y~ ., data=vowel.train, method="gbm", verbose=F)
pred2 = predict(model2, vowel.test)
# tabulate results:
table(pred2,vowel.test$y)
# calculate correct predictions:
sum(diag(table(pred2,vowel.test$y)))/462
#-----------------------------------------------------------------------------------------------
# Question 1
# Load the vowel.train and vowel.test data sets:
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
# Set the variable y to be a factor variable in both the training and test set.
vowel.train$y=as.factor(vowel.train$y)
vowel.test$y=as.factor(vowel.test$y)
set.seed(33833)
# Fit (1) a random forest predictor relating the factor variable y to the remaining variables:
model1 = train(y~ ., data=vowel.train, method="rf", prox=TRUE, ntree=500)
# predict outcome for test data set using the random forest model
pred1 = predict(model1, vowel.test)
# Results
confusionMatrix(vowel.test$y, pred1)
# Fit (2) a boosted predictor using the "gbm" method relating the factor variable y to the remaining variables:
model2= train(y~ ., data=vowel.train, method="gbm", verbose=F)
pred2 = predict(model2, vowel.test)
# Results
confusionMatrix(vowel.test$y, pred2)
#-----------------------------------------------------------------------------------------------
#Question 2
#Load the Alzheimer's data using the following commands
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
#Set the seed to 62433 and predict diagnosis with all the other variables using a random forest ("rf"),
#boosted trees ("gbm") and linear discriminant analysis ("lda") model.
set.seed(62433)
model1 = train(diagnosis~ ., data=vowel.train, method="rf", prox=TRUE, ntree=500)
model2 = train(diagnosis~ ., data=vowel.train, method="gbm", verbose=F)
model3 = train(diagnosis~ ., data=vowel.train, method="lda")
pred1 = predict(model1, testing)
pred2 = predict(model2, testing)
pred3 = predict(model3, testing)
predDf = data.frame(rf.pred=pred1,gbm.pred = pred2, lda.pred = pred3, testing$diagnosis)
#Set the seed to 62433 and predict diagnosis with all the other variables using a random forest ("rf"),
#boosted trees ("gbm") and linear discriminant analysis ("lda") model.
set.seed(62433)
model1 = train(diagnosis~ ., data=training, method="rf", prox=TRUE, ntree=500)
model2 = train(diagnosis~ ., data=training, method="gbm", verbose=F)
model3 = train(diagnosis~ ., data=training, method="lda")
predDf = data.frame(rf.pred=pred1, gbm.pred = pred2, lda.pred = pred3, testing$diagnosis)
pred1 = predict(model1, testing)
pred2 = predict(model2, testing)
pred3 = predict(model3, testing)
predDf = data.frame(rf.pred =pred1, gbm.pred = pred2, lda.pred = pred3, testing$diagnosis)
View(predDf)
predDf = data.frame(rf.pred =pred1, gbm.pred = pred2, lda.pred = pred3, diagnosis=testing$diagnosis)
comboModel = train(diagnosis~ .,method="rf", prox=TRUE, ntree=500)
#Stack the predictions together using random forests ("rf"):
combinedTestData = data.frame(rf.pred =pred1, gbm.pred = pred2, lda.pred = pred3, diagnosis=testing$diagnosis)
comboModel = train(diagnosis~ .,data=combinedTestData, method="rf", prox=TRUE, ntree=500)
# use the resultant model to predict on the test set
comb.pred.test <- predict(comboModel, combinedTestData)
#Stack the predictions together using random forests ("rf"):
combinedTestData = data.frame(rf.pred = pred1, gbm.pred = pred2, lda.pred = pred3, diagnosis=testing$diagnosis)
comboModel = train(diagnosis~ .,data = combinedTestData, method="rf", prox=TRUE, ntree=500)
View(combinedTestData)
combinedTestData = data.frame(rf.pred = pred1, gbm.pred = pred2, lda.pred = pred3, diagnosis=testing$diagnosis)
comboModel = train(diagnosis~ .,data = combinedTestData, method="gam")
# use the resultant model to predict on the test set
comb.pred.test <- predict(comboModel, combinedTestData)
#Stack the predictions together using random forests ("rf"):
combinedTestData = data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis)
comboModel = train(diagnosis~ .,data = combinedTestData, method="rf", prox=TRUE, ntree=500)
#Stack the predictions together using random forests ("rf"):
combinedTestData = data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis)
model4 = train(diagnosis~ .,data = combinedTestData, method="rf", prox=TRUE, ntree=500)
# use the resultant model to predict on the test set
pred1 <- predict(model4, combinedTestData)
#Stack the predictions together using random forests ("rf"):
combinedTestData = data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis)
model4 = train(diagnosis~ .,data = combinedTestData, method="rf", prox=TRUE, ntree=500)
# use the resultant model to predict on the test set
pred4 <- predict(model4, testing)
# confusion matrixes
c1 = confusionMatrix(predict1, testing$diagnosis)
c2 = confusionMatrix(predict2, testing$diagnosis)
c3 = confusionMatrix(predict3, testing$diagnosis)
c4 = confusionMatrix(predict4, testing$diagnosis)
#Stack the predictions together using random forests ("rf"):
combinedTestData = data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis)
model4 = train(diagnosis~ .,data = combinedTestData, method="rf", prox=TRUE, ntree=500)
# use the resultant model to predict on the test set
pred4 <- predict(model4, testing)
# confusion matrixes
c1 = confusionMatrix(pred1, testing$diagnosis)
c2 = confusionMatrix(pred2, testing$diagnosis)
c3 = confusionMatrix(pred3, testing$diagnosis)
c4 = confusionMatrix(pred4, testing$diagnosis)
#Stack the predictions together using random forests ("rf"):
combo = data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis)
model4 = train(diagnosis~ .,data = combo, method="rf", prox=TRUE, ntree=500)
# use the resultant model to predict on the test set
pred4 = predict(model4, testing)
# confusion matrixes
confusionMatrix(pred1, testing$diagnosis)
confusionMatrix(pred2, testing$diagnosis)
confusionMatrix(pred3, testing$diagnosis)
confusionMatrix(pred4, testing$diagnosis)
#Question 2
#Load the Alzheimer's data using the following commands
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
#Set the seed to 62433 and predict diagnosis with all the other variables using a random forest ("rf"),
#boosted trees ("gbm") and linear discriminant analysis ("lda") model:
set.seed(62433)
model1 = train(diagnosis~ ., data=training, method="rf", prox=TRUE, ntree=500)
model2 = train(diagnosis~ ., data=training, method="gbm", verbose=F)
model3 = train(diagnosis~ ., data=training, method="lda")
pred1 = predict(model1, testing)
pred2 = predict(model2, testing)
pred3 = predict(model3, testing)
#Stack the predictions together using random forests ("rf"):
combo = data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis)
model4 = train(diagnosis~ .,data = combo, method="rf", prox=TRUE, ntree=500)
# use the resultant model to predict on the test set:
pred4 = predict(model4, testing)
# confusion matrixes:
confusionMatrix(pred1, testing$diagnosis)
confusionMatrix(pred2, testing$diagnosis)
confusionMatrix(pred3, testing$diagnosis)
confusionMatrix(pred4, testing$diagnosis)
#Set the seed to 62433 and predict diagnosis with all the other variables using a random forest ("rf"),
#boosted trees ("gbm") and linear discriminant analysis ("lda") model:
set.seed(62433)
model1 = train(diagnosis~ ., data=training, method="rf", trControl = trainControl(number = 4))
model2 = train(diagnosis~ ., data=training, method="gbm", verbose=F)
model3 = train(diagnosis~ ., data=training, method="lda")
pred1 = predict(model1, testing)
pred2 = predict(model2, testing)
pred3 = predict(model3, testing)
#Stack the predictions together using random forests ("rf"):
combo = data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis)
model4 = train(diagnosis~ .,data = combo, method="rf", trControl = trainControl(number = 4))
# use the resultant model to predict on the test set:
pred4 = predict(model4, testing)
# confusion matrixes:
confusionMatrix(pred1, testing$diagnosis)
confusionMatrix(pred2, testing$diagnosis)
confusionMatrix(pred3, testing$diagnosis)
confusionMatrix(pred4, testing$diagnosis)
#-----------------------------------------------------------------------------------------------
#Question 3
#Load the concrete data with the commands:
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
View(training)
# load lars package
library(lars)
# perform lasso regression
y <- as.numeric(training[,9])
x <- as.matrix(training[,1:8])
model.lasso = lars(as.matrix(x), y, type="lasso", trace=TRUE)
lambda.lasso = c(model.lasso$lambda,0)
beta = coef(model.lasso)
install.packages("lars")
# load lars package
library(lars)
# perform lasso regression
y <- as.numeric(training[,9])
x <- as.matrix(training[,1:8])
model.lasso = lars(as.matrix(x), y, type="lasso", trace=TRUE)
lambda.lasso = c(model.lasso$lambda,0)
beta = coef(model.lasso)
?plot.enet
??plot.enet
# perform lasso regression
set.seed(233)
lasso.model = train(CompressiveStrength~., data=training, method="lasso")
# perform lasso regression
set.seed(233)
lasso.model = train(CompressiveStrength~., data=training, method="lasso")
plot.enet(lasso.model$finalModel, xvar="penalty", use.color=TRUE)
#-----------------------------------------------------------------------------------------------
#Question 5
#Load the concrete data with the commands:
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
#Set the seed to 325 and fit a support vector machine using the e1071 package to predict Compressive Strength using the default settings. Predict on the testing set. What is the RMSE?
require(e1071)
set.seed(325)
fit=svm(CompressiveStrength ~., data = training )
pred=predict(fit, testing)
accuracy(f = pred, x = testing$CompressiveStrength)
library(forecast)
accuracy(f = pred, x = testing$CompressiveStrength)
install.packages("forecast")
#-----------------------------------------------------------------------------------------------
#Question 5
#Load the concrete data with the commands:
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
#Set the seed to 325 and fit a support vector machine using the e1071 package to predict Compressive Strength using the default settings. Predict on the testing set. What is the RMSE?
require(e1071)
set.seed(325)
fit=svm(CompressiveStrength ~., data = training )
pred=predict(fit, testing)
library(forecast)
accuracy(f = pred, x = testing$CompressiveStrength)
gaData <- read.csv("~/Programming/R/Machine Learning/gaData.csv")
View(gaData)
#Question 4
library(lubridate)  # For year() function below
dat = read.csv("~/Programming/R/Machine Learning/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
install.packages("lubridate")
#-----------------------------------------------------------------------------------------------
#Question 4
library(lubridate)  # For year() function below
dat = read.csv("~/Programming/R/Machine Learning/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
#Fit a model using the bats() function in the forecast package to the training time series:
model= bats(tstrain)
#Then forecast this model for the remaining time points:
fcast <- forecast(model, level = 95, h = h)
# forecast with a 95% ci
fcast = forecast(object = fit, level = 95); fcast
# test accuracy
accuracy(f = fcast, x = training$visitsTumblr)
# forecast with a 95% ci
fcast = forecast(object = model, level = 95); fcast
# test accuracy
accuracy(f = fcast, x = training$visitsTumblr)
#-----------------------------------------------------------------------------------------------
# Question 1
# Load the vowel.train and vowel.test data sets:
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
# Set the variable y to be a factor variable in both the training and test set.
vowel.train$y=as.factor(vowel.train$y)
vowel.test$y=as.factor(vowel.test$y)
set.seed(33833)
# Fit (1) a random forest predictor relating the factor variable y to the remaining variables:
model1 = train(y~ ., data=vowel.train, method="rf", prox=TRUE, ntree=500)
# predict outcome for test data set using the random forest model
pred1 = predict(model1, vowel.test)
# Results
confusionMatrix(vowel.test$y, pred1)
# Fit (2) a boosted predictor using the "gbm" method relating the factor variable y to the remaining variables:
model2= train(y~ ., data=vowel.train, method="gbm", verbose=F)
pred2 = predict(model2, vowel.test)
# Results
confusionMatrix(vowel.test$y, pred2)
pml.training <- read.csv("~/Programming/R/Machine Learning/pml-training.csv")
View(pml.training)
pml.testing <- read.csv("~/Programming/R/Machine Learning/pml-testing.csv")
View(pml.testing)
pml.training <- read.csv("~/Programming/R/Machine Learning/pml-training.csv")
pml.testing <- read.csv("~/Programming/R/Machine Learning/pml-testing.csv")
View(pml.testing)
pml.training = read.csv("pml-training.csv")
pml.training [, colSums(is.na(pml.training )) != nrow(pml.training )]
View(pml.training)
pml.training [, colSums(is.na(pml.training )) != nrow(pml.training )]
pml.training[ , colSums(is.na(pml.training)) == 0]
View(pml.training)
pml.training <- read.csv("~/Programming/R/Machine Learning/pml-training.csv")
View(pml.training)
pml.training = read.csv("pml-training.csv", na.strings=c("NA","NaN", " ") )
pml.training[ , colSums(is.na(pml.training)) == 0]
pml.testing <- read.csv("pml-testing.csv", na.strings=c("NA","NaN", " ") )
pml.training = read.csv("pml-training.csv", na.strings=c("NA","NaN", " ") )
pml.training[ , colSums(is.na(pml.training)) == 0]
pml.training = read.csv("pml-training.csv", na.strings=c("NA","NaN", " ") )
pml.training <- read.csv("~/Programming/R/Machine Learning/pml-training.csv", header=FALSE, na.strings="NA, NAN, \x0C \"")
View(pml.training)
pml.training = read.csv("~/Programming/R/Machine Learning/pml-training.csv", header=TRUE, na.strings=c("NA","NaN", " ") )
pml.training[ , colSums(is.na(pml.training)) == 0]
View(pml.training)
pml.training[ , colSums(is.na(pml.training)) == 0]
subset(pml.training, select=colMeans(is.na(pml.training)) == 0)
test = subset(pml.training, select=colMeans(is.na(pml.training)) == 0)
View(test)
pml.training = read.csv("~/Programming/R/Machine Learning/pml-training.csv", header=TRUE, na.strings=c("NA","NaN", " ") )
pml.training.clean = subset(pml.training, select=colMeans(is.na(pml.training)) == 0)
pml.testing = read.csv("pml-testing.csv", na.strings=c("NA","NaN", " ") )
pml.testing.clean = subset(pml.testing, select=colMeans(is.na(pml.testing)) == 0)
pml.testing = read.csv("~/Programming/R/Machine Learning/pml-testing.csv", na.strings=c("NA","NaN", " ") )
pml.testing.clean = subset(pml.testing, select=colMeans(is.na(pml.testing)) == 0)
View(pml.testing.clean)
pml.training = read.csv("~/Programming/R/Machine Learning/pml-training.csv", header=TRUE, na.strings=c("NA","NaN", '') )
pml.training.clean = subset(pml.training, select=colMeans(is.na(pml.training)) == 0)
View(pml.testing.clean)
View(pml.training.clean)
View(pml.testing.clean)
View(pml.testing)
head(pml.testing)
library(caret)
set.seed(3456)
inTrain = createDataPartition(pml.training$classe, p = .7, list = FALSE)
training = pml.training[inTrain,]
testing = pml.training[-inTrain,]
library("doMC")
# use 4 cores:
registerDoMC(cores=4)
# apply random forest:
modFit = train(classe ~ ., data = training, method="rf", prox=TRUE, ntree=100, allowParallel=TRUE)
# print results:
print(modFit$finalModel)
# predict outcome for test data set using the random forest model:
pred = predict(modFit,testing)
# logic value for whether or not the rf algorithm predicted correctly:
testing$predRight <- pred==testing$classe
# tabulate results:
table(pred,testing$Species)
registerDoMC(cores=4)
# apply random forest:
modFit = train(classe ~ ., data = training, method="rf", prox=TRUE, ntree=100, allowParallel=TRUE)
library("doMC")
# use 4 cores:
registerDoMC(cores=4)
# apply random forest:
modFit = train(classe ~ ., data = training, method="rf", prox=TRUE, ntree=100, allowParallel=TRUE)
setwd("~/")
install.packages("markdown")
---
title: "Practical Machine Learning Course - Final Project"
author: "Jurgen Tas"
date: "12 Jun 2015"
output: html_document
---
## Introduction
Devices such as Jawbone Up, Nike FuelBand, and Fitbit can measure a large amount of personal excersise data. One thing that people regularly do is quantify how much of a particular activity they do. However, they rarely quantify how well they do it. The goal of this project is to predict the manner in which they did the exercise. To this end, we analyse data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. The participants were asked to perform barbell lifts correctly and incorrectly in five different ways. For more information we refer to: http://groupware.les.inf.puc-rio.br/har.
## Analysis
First, we import the raw data using:
```{r}
# import raw data:
pml.training.raw = read.csv("pml-training.csv", header=TRUE, na.strings=c("NA","NaN", '') )
pml.testing.raw = read.csv("pml-testing.csv", header=TRUE, na.strings=c("NA","NaN", " ") )
```
Inspection of this data reveals that there various columns containing only NA's or empty entries. Thus, we decide to remove these columns from both the data sets using:
```{r}
# commands to clean the raw data:
pml.training = subset(pml.training.raw , select=colMeans(is.na(pml.training.raw)) == 0)
pml.testing = subset(pml.testing.raw , select=colMeans(is.na(pml.testing.raw)) == 0)
```
The first seven columns of both resulting data sets do not contain accelerometer measurements or the classe outcome. So, we remove these columns as well.
```{r}
# remove first 7 columns:
pml.training = pml.training[c(-1:-7)]
pml.testing = pml.testing[c(-1:-7)]
```
Remove near zero-Variance Predictors:
```{r}
nzv = nearZeroVar(pml.training)
```
setwd("~/Programming/R/Machine Learning/Final Project")
---
title: "Practical Machine Learning Course - Final Project"
author: "Jurgen Tas"
date: "12 Jun 2015"
output: html_document
---
## Introduction
Devices such as Jawbone Up, Nike FuelBand, and Fitbit can measure a large amount of personal excersise data. One thing that people regularly do is quantify how much of a particular activity they do. However, they rarely quantify how well they do it. The goal of this project is to predict the manner in which they did the exercise. To this end, we analyse data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. The participants were asked to perform barbell lifts correctly and incorrectly in five different ways. For more information we refer to: http://groupware.les.inf.puc-rio.br/har.
## Analysis
First, we import the raw data using:
```{r}
# import raw data:
pml.training.raw = read.csv("pml-training.csv", header=TRUE, na.strings=c("NA","NaN", '') )
pml.testing.raw = read.csv("pml-testing.csv", header=TRUE, na.strings=c("NA","NaN", " ") )
```
Inspection of this data reveals that there various columns containing only NA's or empty entries. Thus, we decide to remove these columns from both the data sets using:
```{r}
# commands to clean the raw data:
pml.training = subset(pml.training.raw , select=colMeans(is.na(pml.training.raw)) == 0)
pml.testing = subset(pml.testing.raw , select=colMeans(is.na(pml.testing.raw)) == 0)
```
The first seven columns of both resulting data sets do not contain accelerometer measurements or the classe outcome. So, we remove these columns as well.
```{r}
# remove first 7 columns:
pml.training = pml.training[c(-1:-7)]
pml.testing = pml.testing[c(-1:-7)]
```
Remove near zero-Variance Predictors:
```{r}
nzv = nearZeroVar(pml.training)
```
library(caret)
---
title: "Practical Machine Learning Course - Final Project"
author: "Jurgen Tas"
date: "12 Jun 2015"
output: html_document
---
## Introduction
Devices such as Jawbone Up, Nike FuelBand, and Fitbit can measure a large amount of personal excersise data. One thing that people regularly do is quantify how much of a particular activity they do. However, they rarely quantify how well they do it. The goal of this project is to predict the manner in which they did the exercise. To this end, we analyse data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. The participants were asked to perform barbell lifts correctly and incorrectly in five different ways. For more information we refer to: http://groupware.les.inf.puc-rio.br/har.
## Analysis
First, we import the raw data using:
```{r}
# import raw data:
pml.training.raw = read.csv("pml-training.csv", header=TRUE, na.strings=c("NA","NaN", '') )
pml.testing.raw = read.csv("pml-testing.csv", header=TRUE, na.strings=c("NA","NaN", " ") )
```
Inspection of this data reveals that there various columns containing only NA's or empty entries. Thus, we decide to remove these columns from both the data sets using:
```{r}
# commands to clean the raw data:
pml.training = subset(pml.training.raw , select=colMeans(is.na(pml.training.raw)) == 0)
pml.testing = subset(pml.testing.raw , select=colMeans(is.na(pml.testing.raw)) == 0)
```
The first seven columns of both resulting data sets do not contain accelerometer measurements or the classe outcome. So, we remove these columns as well.
```{r}
# remove first 7 columns:
pml.training = pml.training[c(-1:-7)]
pml.testing = pml.testing[c(-1:-7)]
```
Remove near zero-Variance Predictors:
```{r}
nzv = nearZeroVar(pml.training)
# import raw data:
pml.training.raw = read.csv("pml-training.csv", header=TRUE, na.strings=c("NA","NaN", '') )
pml.testing.raw = read.csv("pml-testing.csv", header=TRUE, na.strings=c("NA","NaN", " ") )
# import raw data:
pml.training.raw = read.csv("pml-training.csv", header=TRUE, na.strings=c("NA","NaN", '') )
pml.testing.raw = read.csv("pml-testing.csv", header=TRUE, na.strings=c("NA","NaN", " ") )
# commands to clean the raw data:
pml.training = subset(pml.training.raw , select=colMeans(is.na(pml.training.raw)) == 0)
pml.testing = subset(pml.testing.raw , select=colMeans(is.na(pml.testing.raw)) == 0)
# remove first 7 columns:
pml.training = pml.training[c(-1:-7)]
pml.testing = pml.testing[c(-1:-7)]
nzv = nearZeroVar(pml.training)
nzv <- nearZeroVar(pml.training, saveMetrics= TRUE)
nzv[nzv$nzv,][1:10,]
